{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Guide - 1. Keras - 6. Write custom callbacks\n",
    "\n",
    "목차\n",
    "1. Setup\n",
    "2. Introduction to Keras callbacks\n",
    "3. Model methods that take callbacks\n",
    "4. An overview of callback methods\n",
    " 1. Common methods for training/testing/predicting\n",
    " 2. Training specific methods\n",
    " 3. Usage of logsdict\n",
    "5. Examples of Keras callback applications\n",
    " 1. Early Stopping at minimum loss\n",
    " 2. Learning rate scheduling\n",
    " 3. Standard Kears callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-alpha0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introduction to Keras callbacks\n",
    "\n",
    "You can pass a list of callbacks (as the keyword argument callbacks) to any of tf.keras.Model.fit(), tf.keras.Model.evaluate(), and tf.keras.Model.predict() methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Dense(1,activation = 'linear', input_dim=784))\n",
    "    model.compile(optimizer=tf.keras.optimizers.RMSprop(0.1),\n",
    "                 loss='mean_squared_error',\n",
    "                 metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_batch_begin(self, batch, logs=None):\n",
    "        print('Training: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))\n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        print('Training: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))\n",
    "\n",
    "    def on_test_batch_begin(self, batch, logs=None):\n",
    "        print('Evaluating: batch {} begins at {}'.format(batch, datetime.datetime.now().time()))\n",
    "\n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        print('Evaluating: batch {} ends at {}'.format(batch, datetime.datetime.now().time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13:47:28.026985'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(datetime.datetime.now().time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: batch 0 begins at 13:47:29.293912\n",
      "Training: batch 0 ends at 13:47:29.760254\n",
      "Training: batch 1 begins at 13:47:29.760254\n",
      "Training: batch 1 ends at 13:47:29.817101\n",
      "Training: batch 2 begins at 13:47:29.818098\n",
      "Training: batch 2 ends at 13:47:29.882925\n",
      "Training: batch 3 begins at 13:47:29.882925\n",
      "Training: batch 3 ends at 13:47:29.939773\n",
      "Training: batch 4 begins at 13:47:29.940770\n",
      "Training: batch 4 ends at 13:47:29.990665\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "_ = model.fit(x_train, y_train,\n",
    "             batch_size = 64,\n",
    "             epochs=1,\n",
    "             steps_per_epoch=5,\n",
    "             verbose=0,\n",
    "             callbacks = [MyCustomCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model methods that take callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating: batch 0 begins at 13:47:30.026541\n",
      "Evaluating: batch 0 ends at 13:47:30.077406\n",
      "Evaluating: batch 1 begins at 13:47:30.077406\n",
      "Evaluating: batch 1 ends at 13:47:30.086381\n",
      "Evaluating: batch 2 begins at 13:47:30.087379\n",
      "Evaluating: batch 2 ends at 13:47:30.096354\n",
      "Evaluating: batch 3 begins at 13:47:30.096354\n",
      "Evaluating: batch 3 ends at 13:47:30.106332\n",
      "Evaluating: batch 4 begins at 13:47:30.107326\n",
      "Evaluating: batch 4 ends at 13:47:30.116302\n"
     ]
    }
   ],
   "source": [
    "_ = model.evaluate(x_test, y_test, batch_size=128, verbose=0, steps=5,\n",
    "          callbacks=[MyCustomCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. An overview of callback methods\n",
    "### 1. Common methods for training/testing/predicting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- on_(train|test|predict)_begin(self, logs=None)<br>\n",
    "Called at the beginning of fit/evaluate/predict.<br>\n",
    "\n",
    "- on_(train|test|predict)_end(self, logs=None)<br>\n",
    "Called at the end of fit/evaluate/predict.<br>\n",
    "\n",
    "- on_(train|test|predict)_batch_begin(self, batch, logs=None)<br>\n",
    "Called right before processing a batch during training/testing/predicting. Within this method, logs is a dict with batch and size available keys, representing the current batch number and the size of the batch.<br>\n",
    "\n",
    "- on_(train|test|predict)_batch_end(self, batch, logs=None)<br>\n",
    "Called at the end of training/testing/predicting a batch. Within this method, logs is a dict containing the stateful metrics result.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training specific methods\n",
    "\n",
    "- on_epoch_begin(self, epoch, logs=None)<br>\n",
    "Called at the beginning of an epoch during training.\n",
    "\n",
    "- on_epoch_end(self, epoch, logs=None)<br>\n",
    "Called at the end of an epoch during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Usage of logsdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 0, loss is   29.91.\n",
      "For batch 1, loss is  915.56.\n",
      "For batch 2, loss is   26.75.\n",
      "For batch 3, loss is    9.26.\n",
      "For batch 4, loss is    7.49.\n",
      "The average loss for epoch 0 is  197.80 and mean absolute error is    8.38.\n",
      "For batch 0, loss is    6.58.\n",
      "For batch 1, loss is    5.97.\n",
      "For batch 2, loss is    5.55.\n",
      "For batch 3, loss is    5.25.\n",
      "For batch 4, loss is    5.04.\n",
      "The average loss for epoch 1 is    5.68 and mean absolute error is    1.96.\n",
      "For batch 0, loss is    4.88.\n",
      "For batch 1, loss is    4.76.\n",
      "For batch 2, loss is    4.67.\n",
      "For batch 3, loss is    4.58.\n",
      "For batch 4, loss is    4.51.\n",
      "The average loss for epoch 2 is    4.68 and mean absolute error is    1.75.\n"
     ]
    }
   ],
   "source": [
    "class LossAndErrorPrintingCallback(tf.keras.callbacks.Callback):\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        print('For batch {}, loss is {:7.2f}.'.format(batch, logs['loss']))\n",
    "        \n",
    "    def on_test_batch_end(self, batch, logs=None):\n",
    "        print('For batch {}, loss is {:7.2f}.'.format(batch, logs['loss']))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print('The average loss for epoch {} is {:7.2f} and mean absolute error is {:7.2f}.'.format(\n",
    "            epoch, logs['loss'], logs['mae']))\n",
    "\n",
    "model = get_model()\n",
    "_ = model.fit(x_train, \n",
    "              y_train,\n",
    "              batch_size=64,\n",
    "              steps_per_epoch=5,\n",
    "              epochs=3,\n",
    "              verbose=0,\n",
    "              callbacks=[LossAndErrorPrintingCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 0, loss is    4.20.\n",
      "For batch 1, loss is    4.20.\n",
      "For batch 2, loss is    4.20.\n",
      "For batch 3, loss is    4.20.\n",
      "For batch 4, loss is    4.20.\n",
      "For batch 5, loss is    4.20.\n",
      "For batch 6, loss is    4.20.\n",
      "For batch 7, loss is    4.20.\n",
      "For batch 8, loss is    4.20.\n",
      "For batch 9, loss is    4.20.\n",
      "For batch 10, loss is    4.20.\n",
      "For batch 11, loss is    4.20.\n",
      "For batch 12, loss is    4.20.\n",
      "For batch 13, loss is    4.20.\n",
      "For batch 14, loss is    4.20.\n",
      "For batch 15, loss is    4.20.\n",
      "For batch 16, loss is    4.20.\n",
      "For batch 17, loss is    4.20.\n",
      "For batch 18, loss is    4.20.\n",
      "For batch 19, loss is    4.20.\n"
     ]
    }
   ],
   "source": [
    "_ = model.evaluate(x_test, y_test, batch_size=128, verbose=0,steps=20,\n",
    "                  callbacks=[LossAndErrorPrintingCallback()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Examples of Keras callback applications\n",
    "### 1. Early Stopping at minimum loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class EarlyStoppingAtMinLoss(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, patience=0):\n",
    "        super(EarlyStoppingAtMinLoss, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.wait = 0\n",
    "        self.stopped_epoch=0\n",
    "        self.best = np.Inf\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get('loss')\n",
    "        if np.less(current, self.best):\n",
    "            self.best = current\n",
    "            self.wait =0 \n",
    "            self.best_weights = self.model.get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training=True\n",
    "                print('Restoring model weights from the end of the best epoch.')\n",
    "                self.model.set_weights(self.best_weights)\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0:\n",
    "            print('Epoch %05d: early stopping' % (self.stopped_epoch + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch 0, loss is   30.44.\n",
      "For batch 1, loss is  912.69.\n",
      "For batch 2, loss is   27.16.\n",
      "For batch 3, loss is    9.35.\n",
      "For batch 4, loss is    7.55.\n",
      "The average loss for epoch 0 is  197.44 and mean absolute error is    8.38.\n",
      "For batch 0, loss is    6.62.\n",
      "For batch 1, loss is    5.99.\n",
      "For batch 2, loss is    5.56.\n",
      "For batch 3, loss is    5.25.\n",
      "For batch 4, loss is    5.03.\n",
      "The average loss for epoch 1 is    5.69 and mean absolute error is    1.99.\n",
      "For batch 0, loss is    4.87.\n",
      "For batch 1, loss is    4.74.\n",
      "For batch 2, loss is    4.64.\n",
      "For batch 3, loss is    4.56.\n",
      "For batch 4, loss is    4.48.\n",
      "The average loss for epoch 2 is    4.66 and mean absolute error is    1.75.\n",
      "For batch 0, loss is    4.42.\n",
      "For batch 1, loss is    4.36.\n",
      "For batch 2, loss is    4.31.\n",
      "For batch 3, loss is    4.26.\n",
      "For batch 4, loss is    4.21.\n",
      "The average loss for epoch 3 is    4.31 and mean absolute error is    1.66.\n",
      "For batch 0, loss is    4.17.\n",
      "For batch 1, loss is    4.13.\n",
      "For batch 2, loss is    4.11.\n",
      "For batch 3, loss is    4.14.\n",
      "For batch 4, loss is    4.54.\n",
      "The average loss for epoch 4 is    4.22 and mean absolute error is    1.62.\n",
      "For batch 0, loss is    7.90.\n",
      "For batch 1, loss is   35.85.\n",
      "For batch 2, loss is  184.90.\n",
      "For batch 3, loss is  214.60.\n",
      "For batch 4, loss is   82.22.\n",
      "The average loss for epoch 5 is  105.09 and mean absolute error is    8.53.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "_ = model.fit(x_train, y_train,\n",
    "          batch_size=64,\n",
    "          steps_per_epoch=5,\n",
    "          epochs=30,\n",
    "          verbose=0,\n",
    "          callbacks=[LossAndErrorPrintingCallback(), EarlyStoppingAtMinLoss()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Learning rate scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, schedule):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        self.schedule = schedule\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if not hasattr(self.model.optimizer, 'lr'):\n",
    "            raise ValueError('Optimizer must have a \"lr\" attribute.')\n",
    "        lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))\n",
    "        scheduled_lr = self.schedule(epoch, lr)\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, scheduled_lr)\n",
    "        print('Epoch %05d: learning rate is %6.4f' % (epoch, scheduled_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000: learning rate is 0.1000\n",
      "For batch 0, loss is   28.35.\n",
      "For batch 1, loss is  922.45.\n",
      "For batch 2, loss is   25.48.\n",
      "For batch 3, loss is    8.95.\n",
      "For batch 4, loss is    7.34.\n",
      "The average loss for epoch 0 is  198.51 and mean absolute error is    8.34.\n",
      "Epoch 00001: learning rate is 0.1000\n",
      "For batch 0, loss is    6.52.\n",
      "For batch 1, loss is    5.96.\n",
      "For batch 2, loss is    5.57.\n",
      "For batch 3, loss is    5.29.\n",
      "For batch 4, loss is    5.09.\n",
      "The average loss for epoch 1 is    5.69 and mean absolute error is    1.99.\n",
      "Epoch 00002: learning rate is 0.1000\n",
      "For batch 0, loss is    4.94.\n",
      "For batch 1, loss is    4.82.\n",
      "For batch 2, loss is    4.72.\n",
      "For batch 3, loss is    4.64.\n",
      "For batch 4, loss is    4.56.\n",
      "The average loss for epoch 2 is    4.74 and mean absolute error is    1.78.\n",
      "Epoch 00003: learning rate is 0.0500\n",
      "For batch 0, loss is    4.50.\n",
      "For batch 1, loss is    4.46.\n",
      "For batch 2, loss is    4.43.\n",
      "For batch 3, loss is    4.40.\n",
      "For batch 4, loss is    4.37.\n",
      "The average loss for epoch 3 is    4.43 and mean absolute error is    1.70.\n",
      "Epoch 00004: learning rate is 0.0500\n",
      "For batch 0, loss is    4.34.\n",
      "For batch 1, loss is    4.31.\n",
      "For batch 2, loss is    4.28.\n",
      "For batch 3, loss is    4.25.\n",
      "For batch 4, loss is    4.22.\n",
      "The average loss for epoch 4 is    4.28 and mean absolute error is    1.66.\n",
      "Epoch 00005: learning rate is 0.0500\n",
      "For batch 0, loss is    4.19.\n",
      "For batch 1, loss is    4.17.\n",
      "For batch 2, loss is    4.14.\n",
      "For batch 3, loss is    4.11.\n",
      "For batch 4, loss is    4.09.\n",
      "The average loss for epoch 5 is    4.14 and mean absolute error is    1.62.\n",
      "Epoch 00006: learning rate is 0.0100\n",
      "For batch 0, loss is    4.06.\n",
      "For batch 1, loss is    4.06.\n",
      "For batch 2, loss is    4.05.\n",
      "For batch 3, loss is    4.05.\n",
      "For batch 4, loss is    4.04.\n",
      "The average loss for epoch 6 is    4.05 and mean absolute error is    1.59.\n",
      "Epoch 00007: learning rate is 0.0100\n",
      "For batch 0, loss is    4.04.\n",
      "For batch 1, loss is    4.03.\n",
      "For batch 2, loss is    4.02.\n",
      "For batch 3, loss is    4.02.\n",
      "For batch 4, loss is    4.01.\n",
      "The average loss for epoch 7 is    4.02 and mean absolute error is    1.58.\n",
      "Epoch 00008: learning rate is 0.0100\n",
      "For batch 0, loss is    4.00.\n",
      "For batch 1, loss is    4.00.\n",
      "For batch 2, loss is    3.99.\n",
      "For batch 3, loss is    3.98.\n",
      "For batch 4, loss is    3.98.\n",
      "The average loss for epoch 8 is    3.99 and mean absolute error is    1.57.\n",
      "Epoch 00009: learning rate is 0.0050\n",
      "For batch 0, loss is    3.97.\n",
      "For batch 1, loss is    3.97.\n",
      "For batch 2, loss is    3.96.\n",
      "For batch 3, loss is    3.96.\n",
      "For batch 4, loss is    3.95.\n",
      "The average loss for epoch 9 is    3.96 and mean absolute error is    1.57.\n",
      "Epoch 00010: learning rate is 0.0050\n",
      "For batch 0, loss is    3.95.\n",
      "For batch 1, loss is    3.95.\n",
      "For batch 2, loss is    3.94.\n",
      "For batch 3, loss is    3.94.\n",
      "For batch 4, loss is    3.93.\n",
      "The average loss for epoch 10 is    3.94 and mean absolute error is    1.56.\n",
      "Epoch 00011: learning rate is 0.0050\n",
      "For batch 0, loss is    3.93.\n",
      "For batch 1, loss is    3.92.\n",
      "For batch 2, loss is    3.92.\n",
      "For batch 3, loss is    3.91.\n",
      "For batch 4, loss is    3.91.\n",
      "The average loss for epoch 11 is    3.92 and mean absolute error is    1.55.\n",
      "Epoch 00012: learning rate is 0.0010\n",
      "For batch 0, loss is    3.90.\n",
      "For batch 1, loss is    3.90.\n",
      "For batch 2, loss is    3.90.\n",
      "For batch 3, loss is    3.90.\n",
      "For batch 4, loss is    3.89.\n",
      "The average loss for epoch 12 is    3.90 and mean absolute error is    1.55.\n",
      "Epoch 00013: learning rate is 0.0010\n",
      "For batch 0, loss is    3.89.\n",
      "For batch 1, loss is    3.89.\n",
      "For batch 2, loss is    3.89.\n",
      "For batch 3, loss is    3.89.\n",
      "For batch 4, loss is    3.89.\n",
      "The average loss for epoch 13 is    3.89 and mean absolute error is    1.55.\n",
      "Epoch 00014: learning rate is 0.0010\n",
      "For batch 0, loss is    3.89.\n",
      "For batch 1, loss is    3.88.\n",
      "For batch 2, loss is    3.88.\n",
      "For batch 3, loss is    3.88.\n",
      "For batch 4, loss is    3.88.\n",
      "The average loss for epoch 14 is    3.88 and mean absolute error is    1.54.\n"
     ]
    }
   ],
   "source": [
    "LR_SCHEDULE = [(3, 0.05), (6, 0.01), (9, 0.005), (12, 0.001)]\n",
    "\n",
    "def lr_schedule(epoch, lr):\n",
    "    if epoch < LR_SCHEDULE[0][0] or epoch > LR_SCHEDULE[-1][0]:\n",
    "        return lr\n",
    "    for i in range(len(LR_SCHEDULE)):\n",
    "        if epoch == LR_SCHEDULE[i][0]:\n",
    "            return LR_SCHEDULE[i][1]\n",
    "    return lr\n",
    "\n",
    "model = get_model()\n",
    "_ = model.fit(x_train, y_train,\n",
    "          batch_size=64,\n",
    "          steps_per_epoch=5,\n",
    "          epochs=15,\n",
    "          verbose=0,\n",
    "          callbacks=[LossAndErrorPrintingCallback(), LearningRateScheduler(lr_schedule)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Standard Kears callbacks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf20a",
   "language": "python",
   "name": "tf20a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
