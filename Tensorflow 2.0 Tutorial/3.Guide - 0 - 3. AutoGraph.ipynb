{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Guide - 3. AutoGraph\n",
    "\n",
    "목차\n",
    "1. Setup\n",
    "2. The tf.function decorator\n",
    "3. Use Python control flow\n",
    "4. Keras and AutoGraph\n",
    "5. Side effect\n",
    "6. Example: training a simple model\n",
    " - Download data\n",
    " - Define the model\n",
    " - Define the training loop\n",
    "7. Batching\n",
    "\n",
    "URL : https://www.tensorflow.org/alpha/guide/autograph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " TF 2.0: Functions, not Sessions\n",
    " \n",
    "https://github.com/tensorflow/community/blob/master/rfcs/20180918-functions-not-sessions-20.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-alpha0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The tf.function decorator\n",
    "\n",
    "When you annotate a function with tf.function, you can still call it like any other function. <br>\n",
    "But it will be compiled into a graph, which means you get the benefits of faster execution, running on GPU or TPU, or exporting to SavedModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=25, shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0.35023785, 0.6246093 , 0.8395574 ],\n",
       "       [0.54186475, 0.6748481 , 0.988986  ],\n",
       "       [0.5845109 , 0.26622313, 0.6095227 ]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def simple__nn__layer(x,y):\n",
    "    return tf.nn.relu(tf.matmul(x,y))\n",
    "\n",
    "x = tf.random.uniform((3,3))\n",
    "y = tf.random.uniform((3,3))\n",
    "\n",
    "simple__nn__layer(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=51, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[0.23317024, 0.51967406],\n",
       "       [0.4456082 , 0.4148772 ]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def simple__nn__layer(x,y):\n",
    "    return tf.nn.relu(tf.matmul(x,y))\n",
    "\n",
    "x = tf.random.uniform((2,3))\n",
    "y = tf.random.uniform((3,2))\n",
    "\n",
    "simple__nn__layer(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x14f954e2320>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple__nn__layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=65, shape=(3,), dtype=int32, numpy=array([3, 5, 7])>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear_layer(x):\n",
    "    return 2*x + 1\n",
    "\n",
    "@tf.function\n",
    "def deep_net(x):\n",
    "    return tf.nn.relu(linear_layer(x))\n",
    "\n",
    "deep_net(tf.constant((1,2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager conv: 0.0027249\n",
      "Function conv: 0.0020799\n",
      "Note how there's not much difference in performance for convolutions\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "conv_layer = tf.keras.layers.Conv2D(100,3)\n",
    "\n",
    "@tf.function\n",
    "def conv_fn(image):\n",
    "    return conv_layer(image)\n",
    "\n",
    "image = tf.zeros([1,200,200,100])\n",
    "\n",
    "conv_layer(image); conv_fn(image)\n",
    "\n",
    "print('Eager conv:', timeit.timeit(lambda: conv_layer(image), number=10))\n",
    "print(\"Function conv:\", timeit.timeit(lambda: conv_fn(image), number=10))\n",
    "print(\"Note how there's not much difference in performance for convolutions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eager lstm: 0.0465313\n",
      "function lstm: 0.005065899999999984\n"
     ]
    }
   ],
   "source": [
    "lstm_cell  = tf.keras.layers.LSTMCell(10)\n",
    "\n",
    "@tf.function\n",
    "def lstm_fn(input, state):\n",
    "    return lstm_cell(input, state)\n",
    "\n",
    "input = tf.zeros([10,10])\n",
    "state = [tf.zeros([10,10])]*2\n",
    "\n",
    "lstm_cell(input, state); lstm_fn(input,state)\n",
    "print(\"eager lstm:\", timeit.timeit(lambda: lstm_cell(input, state), number=10))\n",
    "print(\"function lstm:\", timeit.timeit(lambda: lstm_fn(input, state), number=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use Python control flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "square_if_positive(2) = 4\n",
      "square_if_positive(-2) = 0\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def square_if_positive(x):\n",
    "    if x > 0:\n",
    "        x = x*x\n",
    "    else:\n",
    "        x=0\n",
    "    return x\n",
    "\n",
    "print('square_if_positive(2) = {}'.format(square_if_positive(tf.constant(2))))\n",
    "print('square_if_positive(-2) = {}'.format(square_if_positive(tf.constant(-2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1648, shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def sum_even(items):\n",
    "    s = 0\n",
    "    for c in items:\n",
    "        if c % 2 > 0:\n",
    "            continue\n",
    "        s += c\n",
    "    return s\n",
    "\n",
    "\n",
    "sum_even(tf.constant([10, 12, 15, 20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from __future__ import print_function\n",
      "\n",
      "def tf__sum_even(items):\n",
      "  try:\n",
      "    with ag__.function_scope('sum_even'):\n",
      "      do_return = False\n",
      "      retval_ = None\n",
      "      s = 0\n",
      "\n",
      "      def loop_body(loop_vars, s_2):\n",
      "        with ag__.function_scope('loop_body'):\n",
      "          c = loop_vars\n",
      "          continue_ = False\n",
      "          cond = ag__.gt(c % 2, 0)\n",
      "\n",
      "          def if_true():\n",
      "            with ag__.function_scope('if_true'):\n",
      "              continue_ = True\n",
      "              return continue_\n",
      "\n",
      "          def if_false():\n",
      "            with ag__.function_scope('if_false'):\n",
      "              return continue_\n",
      "          continue_ = ag__.if_stmt(cond, if_true, if_false)\n",
      "          cond_1 = ag__.not_(continue_)\n",
      "\n",
      "          def if_true_1():\n",
      "            with ag__.function_scope('if_true_1'):\n",
      "              s_1, = s_2,\n",
      "              s_1 += c\n",
      "              return s_1\n",
      "\n",
      "          def if_false_1():\n",
      "            with ag__.function_scope('if_false_1'):\n",
      "              return s_2\n",
      "          s_2 = ag__.if_stmt(cond_1, if_true_1, if_false_1)\n",
      "          return s_2,\n",
      "      s, = ag__.for_stmt(items, None, loop_body, (s,))\n",
      "      do_return = True\n",
      "      retval_ = s\n",
      "      return retval_\n",
      "  except:\n",
      "    ag__.rewrite_graph_construction_error(ag_source_map__)\n",
      "\n",
      "\n",
      "\n",
      "tf__sum_even.autograph_info__ = {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tf.autograph.to_code(sum_even.python_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fizz\n",
      "1\n",
      "2\n",
      "Fizz\n",
      "4\n",
      "Buzz\n",
      "Fizz\n",
      "7\n",
      "8\n",
      "Fizz\n",
      "Buzz\n",
      "11\n",
      "Fizz\n",
      "13\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def fizzbuzz(n):\n",
    "  msg = tf.constant('')\n",
    "  for i in tf.range(n):\n",
    "    if tf.equal(i % 3, 0):\n",
    "      tf.print('Fizz')\n",
    "    elif tf.equal(i % 5, 0):\n",
    "      tf.print('Buzz')\n",
    "    else:\n",
    "      tf.print(i)\n",
    "\n",
    "fizzbuzz(tf.constant(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Keras and AutoGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1767, shape=(2,), dtype=int32, numpy=array([-1, -2])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomModel(tf.keras.models.Model):\n",
    "    @tf.function\n",
    "    def call(self, input_data):\n",
    "        if tf.reduce_mean(input_data)>0:\n",
    "            return input_data\n",
    "        else:\n",
    "            return input_data//2\n",
    "        \n",
    "model = CustomModel()\n",
    "model(tf.constant([-2,-4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Side effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=7>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable(5)\n",
    "\n",
    "@tf.function\n",
    "def find_next_odd():\n",
    "    v.assign(v + 1)\n",
    "    if tf.equal(v % 2, 0):\n",
    "        v.assign(v + 1)\n",
    "        \n",
    "find_next_odd()\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Example: training a simple model\n",
    "\n",
    "- Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_mnist_features_and_labels(x,y):\n",
    "    x = tf.cast(x, tf.float32) / 255\n",
    "    y = tf.cast(y, tf.int64)\n",
    "    return x,y\n",
    "\n",
    "def mnist_dataset():\n",
    "    (x,y),_ = tf.keras.datasets.mnist.load_data()\n",
    "    ds = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "    ds = ds.map(prepare_mnist_features_and_labels)\n",
    "    ds = ds.take(20000).shuffle(20000).batch(100)\n",
    "    return ds\n",
    "\n",
    "train_dataset = mnist_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential((\n",
    "    tf.keras.layers.Reshape(target_shape=(28 * 28,), input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(100, activation='relu'),\n",
    "    tf.keras.layers.Dense(10)))\n",
    "model.build()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 10 : loss 1.764835 ; accuracy 0.358\n",
      "Step 20 : loss 1.21475899 ; accuracy 0.53\n",
      "Step 30 : loss 0.840928 ; accuracy 0.611666679\n",
      "Step 40 : loss 0.6430071 ; accuracy 0.66525\n",
      "Step 50 : loss 0.468872726 ; accuracy 0.6982\n",
      "Step 60 : loss 0.438222975 ; accuracy 0.7265\n",
      "Step 70 : loss 0.50134033 ; accuracy 0.747714281\n",
      "Step 80 : loss 0.354690462 ; accuracy 0.765125\n",
      "Step 90 : loss 0.375266343 ; accuracy 0.778222203\n",
      "Step 100 : loss 0.238421515 ; accuracy 0.7891\n",
      "Step 110 : loss 0.307576209 ; accuracy 0.800727248\n",
      "Step 120 : loss 0.2816315 ; accuracy 0.809\n",
      "Step 130 : loss 0.344660074 ; accuracy 0.815923095\n",
      "Step 140 : loss 0.367471933 ; accuracy 0.822357118\n",
      "Step 150 : loss 0.383237481 ; accuracy 0.827266693\n",
      "Step 160 : loss 0.304164231 ; accuracy 0.832437515\n",
      "Step 170 : loss 0.280951023 ; accuracy 0.83764708\n",
      "Step 180 : loss 0.172473654 ; accuracy 0.84283334\n",
      "Step 190 : loss 0.261466265 ; accuracy 0.847473681\n",
      "Step 200 : loss 0.407042474 ; accuracy 0.8518\n",
      "Final step 200 : loss tf.Tensor(0.40704247, shape=(), dtype=float32) ; accuracy tf.Tensor(0.8518, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "compute_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "compute_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "\n",
    "def train_one_step(model, optimizer, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x)\n",
    "        loss = compute_loss(y, logits)\n",
    "\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    compute_accuracy(y, logits)\n",
    "    return loss\n",
    "\n",
    "\n",
    "#@tf.function\n",
    "def train(model, optimizer):\n",
    "    train_ds = mnist_dataset()\n",
    "    step = 0\n",
    "    loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    for x, y in train_ds:\n",
    "        step += 1\n",
    "        loss = train_one_step(model, optimizer, x, y)\n",
    "        if tf.equal(step % 10, 0):\n",
    "            tf.print('Step', step, ': loss', loss, '; accuracy', compute_accuracy.result())\n",
    "    return step, loss, accuracy\n",
    "\n",
    "step, loss, accuracy = train(model, optimizer)\n",
    "print('Final step', step, ': loss', loss, '; accuracy', compute_accuracy.result())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-5, -4, -3, -2, -1, 0, 1, 4, 9, 16]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def square_if_positive(x):\n",
    "    return [i ** 2 if i > 0 else i for i in x]\n",
    "\n",
    "\n",
    "square_if_positive(range(-5, 5)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=39134, shape=(10,), dtype=int32, numpy=array([-5, -4, -3, -2, -1,  0,  1,  4,  9, 16])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def square_if_positive_naive(x):\n",
    "    result = tf.TensorArray(tf.int32, size=x.shape[0])\n",
    "    for i in tf.range(x.shape[0]):\n",
    "        if x[i] > 0:\n",
    "            result = result.write(i, x[i] ** 2)\n",
    "        else:\n",
    "            result = result.write(i, x[i])\n",
    "    return result.stack()\n",
    "\n",
    "\n",
    "square_if_positive_naive(tf.range(-5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=39144, shape=(10,), dtype=int32, numpy=array([-5, -4, -3, -2, -1,  0,  1,  4,  9, 16])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def square_if_positive_vectorized(x):\n",
    "    return tf.where(x > 0, x ** 2, x)\n",
    "\n",
    "\n",
    "square_if_positive_vectorized(tf.range(-5, 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf20a",
   "language": "python",
   "name": "tf20a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
